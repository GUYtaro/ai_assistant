# main.py
# ================================
# ü§ñ AI Assistant (Complete Version with Copilot Vision)
# ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Push-to-Talk, Copilot Vision, Screen Sharing
# ================================

import re
import sys
import urllib.parse
from PyQt6.QtWidgets import QApplication, QWidget, QVBoxLayout, QLabel, QPushButton, QHBoxLayout, QScrollArea, QFrame
from PyQt6.QtCore import QObject, pyqtSignal, pyqtSlot, QThread
import sounddevice as sd
import numpy as np

# Import core modules
from core.llm_client import LLMClient
from core.stt_client import STTClient
from core.tts_client import TTSClient
from core.vision_system import VisionSystem
from core.command_parser import CommandParser
from core.automation_executor import AutomationExecutor
from core.screen_capturer import screenshot_data_uri, screenshot_pil
from core.screen_reader import ScreenReader
from core.hotkey_listener import HotkeyListener
from core.app_launcher import AppLauncher
from core.smart_app_launcher import SmartAppLauncher 
from gui.assistant_bar import AssistantBar

# Import for Copilot Vision
try:
    import mss
    _HAS_MSS = True
except ImportError:
    print("[WARNING] ‡πÑ‡∏°‡πà‡∏û‡∏ö mss, Copilot Vision ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
    _HAS_MSS = False


class ScreenSharePanel(QWidget):
    """
    üñ•Ô∏è ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Copilot Vision
    ‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏ä‡∏£‡πå‡πÉ‡∏´‡πâ AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    """
    
    share_requested = pyqtSignal(int, str)  # monitor_id, description

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("üß† Copilot Vision - Share Screen")
        self.setFixedSize(400, 400)
        self.layout = QVBoxLayout(self)

        # Title
        title = QLabel("üß† Copilot Vision")
        title.setStyleSheet("font-size:18px; font-weight:bold; margin:10px;")
        self.layout.addWidget(title)

        # Description
        desc = QLabel("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏ä‡∏£‡πå‡πÉ‡∏´‡πâ AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:")
        desc.setStyleSheet("margin:5px; color:#888;")
        self.layout.addWidget(desc)

        # Scroll area for monitors list
        self.scroll = QScrollArea()
        self.scroll.setWidgetResizable(True)
        self.layout.addWidget(self.scroll)

        # Content for scroll area
        content = QWidget()
        self.scroll.setWidget(content)
        vbox = QVBoxLayout(content)

        # Display available monitors
        if _HAS_MSS:
            with mss.mss() as sct:
                # sct.monitors[0] is the combined screen, [1:] are individual monitors
                for i, mon in enumerate(sct.monitors[1:], start=1):
                    self._add_monitor_frame(vbox, i, mon)
        else:
            error_label = QLabel("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡πÑ‡∏î‡πâ\n‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á: pip install mss")
            error_label.setStyleSheet("color:red; margin:10px;")
            vbox.addWidget(error_label)

        vbox.addStretch()

        # Close button
        close_btn = QPushButton("‡∏õ‡∏¥‡∏î")
        close_btn.setStyleSheet("padding:8px; margin:10px;")
        close_btn.clicked.connect(self.close)
        self.layout.addWidget(close_btn)

    def _add_monitor_frame(self, layout, monitor_id, monitor_info):
        """‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ü‡∏£‡∏°‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠"""
        frame = QFrame()
        frame.setStyleSheet("""
            QFrame {
                border: 1px solid #555; 
                border-radius: 8px; 
                padding: 10px;
                margin: 5px;
                background: #2a2a2a;
            }
            QFrame:hover {
                background: #333333;
                border-color: #777;
            }
        """)
        
        frame_layout = QHBoxLayout(frame)

        # Monitor info
        info_text = f"üñ•Ô∏è ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ {monitor_id}\n{monitor_info['width']} x {monitor_info['height']} pixels"
        label = QLabel(info_text)
        label.setStyleSheet("font-size:12px;")
        frame_layout.addWidget(label)
        
        frame_layout.addStretch()
        
        # Share button
        btn = QPushButton("‡πÅ‡∏ä‡∏£‡πå")
        btn.setStyleSheet("""
            QPushButton {
                background: #4CAF50;
                color: white;
                border: none;
                padding: 6px 12px;
                border-radius: 4px;
                font-weight: bold;
            }
            QPushButton:hover {
                background: #45a049;
            }
        """)
        btn.clicked.connect(lambda _, m=monitor_id: self._on_share_clicked(m))
        frame_layout.addWidget(btn)
        
        layout.addWidget(frame)

    def _on_share_clicked(self, monitor_id):
        """‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡πÅ‡∏ä‡∏£‡πå‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠"""
        description = f"‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ {monitor_id}"
        print(f"[Vision] ‡πÅ‡∏ä‡∏£‡πå‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ {monitor_id} ‡πÉ‡∏´‡πâ AI")
        self.share_requested.emit(monitor_id, description)
        self.close()


class VoiceRecorder(QObject):
    """
    üé§ ‡∏ï‡∏±‡∏ß‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏ö‡∏ö Push-to-Talk
    ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏î‡∏Ñ‡πâ‡∏≤‡∏á‡∏õ‡∏∏‡πà‡∏°‡πÑ‡∏°‡∏Ñ‡πå ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏à‡∏¥‡∏ï‡∏≠‡∏•
    """
    
    recording_started = pyqtSignal()
    recording_stopped = pyqtSignal(object)  # ‡∏™‡πà‡∏á audio data ‡∏Å‡∏•‡∏±‡∏ö
    
    def __init__(self, stt_client: STTClient):
        super().__init__()
        self.stt = stt_client
        self.is_recording = False
        self.audio_data = []
        self.sample_rate = 16000  # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö Whisper
        
    def start_recording(self):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á"""
        if self.is_recording:
            return
        
        self.is_recording = True
        self.audio_data = []
        
        print("[VoiceRecorder] üî¥ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á...")
        self.recording_started.emit()
        
        # Callback function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á
        def audio_callback(indata, frames, time, status):
            if status:
                print(f"[VoiceRecorder] Status: {status}")
            if self.is_recording:
                self.audio_data.append(indata.copy())
        
        # ‡πÄ‡∏£‡∏¥‡πà‡∏° stream ‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á
        self.stream = sd.InputStream(
            samplerate=self.sample_rate,
            channels=1,  # ‡πÇ‡∏°‡πÇ‡∏ô
            callback=audio_callback,
            dtype=np.float32  # ‡πÉ‡∏ä‡πâ float32 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Whisper
        )
        self.stream.start()
    
    def stop_recording(self):
        """‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏±‡∏ö"""
        if not self.is_recording:
            return
        
        self.is_recording = False
        
        # ‡∏´‡∏¢‡∏∏‡∏î stream
        if hasattr(self, 'stream'):
            self.stream.stop()
            self.stream.close()
        
        print("[VoiceRecorder] ‚èπÔ∏è ‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if len(self.audio_data) == 0:
            print("[VoiceRecorder] ‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
            self.recording_stopped.emit(None)
            return
        
        # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        audio_array = np.concatenate(self.audio_data, axis=0)
        audio_float32 = audio_array.flatten().astype(np.float32)
        
        duration = len(audio_float32) / self.sample_rate
        print(f"[VoiceRecorder] ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ {duration:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
        
        # ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Å‡∏•‡∏±‡∏ö
        self.recording_stopped.emit(audio_float32)


class TranscriptionWorker(QThread):
    """
    üîÑ Worker thread ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
    ‡πÉ‡∏ä‡πâ Whisper model ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
    """
    
    transcription_done = pyqtSignal(str)  # ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏î‡πâ
    
    def __init__(self, stt_client: STTClient, audio_data):
        super().__init__()
        self.stt = stt_client
        self.audio_data = audio_data
    
    def run(self):
        """‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        try:
            print("[TranscriptionWorker] üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°...")
            
            # ‡πÉ‡∏ä‡πâ Whisper model ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            text = self.stt.model.transcribe(
                self.audio_data,
                language="th",  # ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
                fp16=False      # ‡πÉ‡∏ä‡πâ float32 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
            )["text"].strip()
            
            print(f"[TranscriptionWorker] ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏î‡πâ: {text}")
            self.transcription_done.emit(text)
            
        except Exception as e:
            print(f"[TranscriptionWorker] ‚ùå Error: {e}")
            self.transcription_done.emit("")


class AssistantContext:
    """
    üß† Context Memory ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢
    ‡∏à‡∏î‡∏à‡∏≥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
    """
    
    def __init__(self):
        self.memory = {
            "last_opened_app": None,
            "recent_commands": [],
            "favorite_apps": {},
            "user_preferences": {
                "preferred_browser": "chrome",
                "language": "th"
            }
        }
        self.max_history = 10  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ
    
    def record_command(self, command: str, result: str):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå"""
        from datetime import datetime
        self.memory["recent_commands"].append({
            "command": command,
            "result": result,
            "timestamp": datetime.now().strftime("%H:%M:%S")
        })
        # ‡∏•‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏Å‡πà‡∏≤‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
        if len(self.memory["recent_commands"]) > self.max_history:
            self.memory["recent_commands"].pop(0)
    
    def record_app_launch(self, app_name: str, success: bool):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô"""
        self.memory["last_opened_app"] = app_name
        if app_name not in self.memory["favorite_apps"]:
            self.memory["favorite_apps"][app_name] = {"launch_count": 0, "success_count": 0}
        self.memory["favorite_apps"][app_name]["launch_count"] += 1
        if success:
            self.memory["favorite_apps"][app_name]["success_count"] += 1
    
    def get_smart_suggestion(self, partial_command: str) -> str:
        """‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"""
        partial_lower = partial_command.lower()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        for cmd in reversed(self.memory["recent_commands"]):
            if partial_lower in cmd["command"].lower():
                return f"‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ô‡∏µ‡πâ: '{cmd['command']}' -> {cmd['result']}"
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏õ‡∏¥‡∏î
        for app_name, stats in self.memory["favorite_apps"].items():
            if partial_lower in app_name.lower():
                success_rate = (stats["success_count"] / stats["launch_count"]) * 100
                return f"‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏õ‡∏¥‡∏î '{app_name}' {stats['launch_count']} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á (‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à {success_rate:.0f}%)"
        
        return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"
    
    def get_context_summary(self) -> str:
        """‡∏™‡∏£‡∏∏‡∏õ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î"""
        summary = []
        if self.memory["last_opened_app"]:
            summary.append(f"‡πÄ‡∏õ‡∏¥‡∏î‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {self.memory['last_opened_app']}")
        if self.memory["recent_commands"]:
            summary.append(f"‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {len(self.memory['recent_commands'])} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        if self.memory["favorite_apps"]:
            top_app = max(self.memory["favorite_apps"].items(), 
                         key=lambda x: x[1]["launch_count"], default=(None, None))
            if top_app[0]:
                summary.append(f"‡πÅ‡∏≠‡∏õ‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°: {top_app[0]}")
        return " | ".join(summary) if summary else "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î"


class SmartCommandParser:
    """
    üß© ‡∏ï‡∏±‡∏ß‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞
    ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ï‡πà‡∏≤‡∏á‡πÜ
    """
    
    def __init__(self, llm_client):
        self.llm = llm_client
        # Mapping ‡∏Ñ‡∏≥‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
        self.thai_to_english_map = {
            "‡∏î‡∏¥‡∏™‡∏Ñ‡∏≠‡∏£‡πå‡∏ï": "discord", "‡∏î‡∏¥‡∏™‡∏Ñ‡∏≠‡∏£‡πå‡∏î": "discord", "‡∏î‡∏¥‡∏™‡∏Ñ‡∏≠‡∏î": "discord",
            "‡πÑ‡∏•‡∏ô‡πå": "line", "‡∏•‡∏≤‡∏¢": "line",
            "‡∏™‡∏õ‡∏≠‡∏ï‡∏¥‡πÑ‡∏ü": "spotify", "‡∏™‡∏õ‡∏≠‡∏ï‡∏ï‡∏¥‡∏ü‡∏≤‡∏¢": "spotify",
            "‡πÇ‡∏Ñ‡∏£‡∏°": "chrome", "‡πÑ‡∏Ñ‡∏£‡∏°‡πå": "chrome",
            "‡πÄ‡∏≠‡πá‡∏î‡∏à‡πå": "edge", "‡∏ü‡∏≤‡∏¢‡∏£‡πå‡∏ü‡∏≠‡∏Å‡∏ã‡πå": "firefox",
            "‡∏™‡∏ï‡∏µ‡∏°": "steam", "‡∏ß‡∏µ‡πÄ‡∏≠‡∏™‡πÇ‡∏Ñ‡πâ‡∏î": "vscode",
            "‡πÇ‡∏ô‡πâ‡∏ï‡πÅ‡∏û‡∏î": "notepad", "‡πÅ‡∏Ñ‡∏•‡∏Ñ‡∏π‡πÄ‡∏•‡πÄ‡∏ï‡∏≠‡∏£‡πå": "calculator",
            "‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏¥‡∏î‡πÄ‡∏•‡∏Ç": "calculator", "‡πÄ‡∏û‡πâ‡∏ô‡∏ó‡πå": "paint",
            "‡πÇ‡∏£‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏ã‡πå": "roblox", "‡∏°‡∏≤‡∏¢‡∏Ñ‡∏£‡∏≤‡∏ü‡∏ó‡πå": "minecraft",
            "‡∏ß‡∏≠‡∏£‡πå‡∏ò‡∏±‡∏ô‡πÄ‡∏î‡∏≠‡∏£‡πå": "war thunder", "‡∏ß‡∏µ‡πÄ‡∏≠‡πá‡∏°‡πÅ‡∏ß‡∏£‡πå": "vmware",
            "‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏î": "word", "‡πÄ‡∏≠‡πá‡∏Å‡πÄ‡∏ã‡∏•": "excel",
            "‡∏û‡∏≤‡∏ß‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏û‡∏≠‡∏¢‡∏ó‡πå": "powerpoint", "‡πÄ‡∏≠‡∏≤‡∏ó‡πå‡∏•‡∏∏‡∏Ñ": "outlook",
            "‡∏ó‡∏µ‡∏°‡∏™‡πå": "teams", "‡∏ã‡∏π‡∏°": "zoom", "‡∏™‡πÅ‡∏•‡πá‡∏Å": "slack",
            "‡∏°‡∏≤‡∏¢‡πÄ‡∏≠‡∏ã‡∏∏‡∏™": "my asus", "‡∏≠‡∏≤‡∏£‡πå‡∏°‡∏π‡∏£‡∏µ‡πà‡πÄ‡∏Ñ‡∏£‡∏ó": "armoury crate"
        }
    
    def is_open_command(self, text: str) -> bool:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡πÅ‡∏≠‡∏õ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        return any(word in text.lower() for word in ["‡πÄ‡∏õ‡∏¥‡∏î", "open", "launch", "start", "run"])
    
    def extract_app_name_from_command(self, text: str) -> str:
        """‡πÅ‡∏¢‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á"""
        text_lower = text.lower()
        remove_words = ["‡πÄ‡∏õ‡∏¥‡∏î", "open", "launch", "start", "run", "‡∏ú‡πà‡∏≤‡∏ô", "‡πÉ‡∏ô", "‡∏î‡πâ‡∏ß‡∏¢", "‡∏´‡∏ô‡πà‡∏≠‡∏¢"]
        app_name = text_lower
        for word in remove_words:
            app_name = app_name.replace(word, "").strip()
        app_name_english = self._translate_thai_to_english(app_name)
        if app_name_english != app_name:
            print(f"üîÑ [Translation] '{app_name}' ‚Üí '{app_name_english}'")
        return app_name_english
    
    def _translate_thai_to_english(self, thai_text: str) -> str:
        """‡πÅ‡∏õ‡∏•‡∏Ñ‡∏≥‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©"""
        thai_text = thai_text.strip()
        if thai_text in self.thai_to_english_map:
            return self.thai_to_english_map[thai_text]
        for thai, english in self.thai_to_english_map.items():
            if thai in thai_text:
                return english
        return thai_text
    
    def extract_url(self, text: str) -> str:
        """‡πÅ‡∏¢‡∏Å URL ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á"""
        url_map = {
            "youtube": "https://youtube.com", "‡∏¢‡∏π‡∏ó‡∏π‡∏õ": "https://youtube.com",
            "google": "https://google.com", "facebook": "https://facebook.com",
            "chatgpt": "https://chat.openai.com", "claude": "https://claude.ai"
        }
        for keyword, url in url_map.items():
            if keyword in text.lower():
                return url
        return None
    
    def extract_search_query(self, text: str) -> str:
        """‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á"""
        if "‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤" not in text.lower() and "search" not in text.lower():
            return None
        query = text.lower().replace("‡πÄ‡∏õ‡∏¥‡∏î", "").replace("‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤", "").strip()
        if query:
            return f"https://www.google.com/search?q={urllib.parse.quote(query)}"
        return None


class AssistantCore(QObject):
    """
    üß† Core System ‡∏Ç‡∏≠‡∏á AI Assistant
    ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ô‡∏á‡∏≤‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á modules
    """
    
    # ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏Å‡∏±‡∏ö GUI
    status_updated = pyqtSignal(str)          # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
    response_ready = pyqtSignal(str)          # ‡∏™‡πà‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö
    voice_input_received = pyqtSignal(str)    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á
    
    def __init__(self):
        super().__init__()
        self.setup_core_systems()
        
    def setup_core_systems(self):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
        try:
            # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ core modules
            self.llm = LLMClient()                    # AI Language Model
            self.stt = STTClient(model_size="medium", language="th")  # Speech-to-Text
            self.tts = TTSClient(lang="th")           # Text-to-Speech  
            self.vision = VisionSystem()              # Vision Analysis
            self.parser = CommandParser(llm_client=self.llm)  # Command Parser
            self.executor = AutomationExecutor(monitor=1)     # Automation
            self.launcher = AppLauncher()             # App Launcher
            self.smart_launcher = SmartAppLauncher()  # Smart App Launcher
            
            # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ systems ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
            self.context = AssistantContext()         # Context Memory
            self.command_parser = SmartCommandParser(llm_client=self.llm)  # Smart Parser
            
            # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Voice Recorder ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Push-to-Talk
            self.voice_recorder = VoiceRecorder(self.stt)
            self.voice_recorder.recording_stopped.connect(self.on_audio_recorded)
            
            # ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
            self.chat_history = [{
                "role": "system", 
                "content": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥"
            }]
            
            # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Hotkey Listener (‡∏õ‡∏∏‡πà‡∏° F4)
            self.hotkey_listener = HotkeyListener(
                callback_start=self.handle_voice_f4,
                hotkey="f4",
                cooldown=2.0
            )
            
            self.status_updated.emit("‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‚úÖ")
            print("=== ü§ñ AI Assistant (Complete with Copilot Vision) ===")
            
        except Exception as e:
            error_msg = f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö: {str(e)}"
            self.status_updated.emit(error_msg)
            print(f"Error setting up systems: {e}")

    # =====================================================
    # üé§ Voice Recording Methods
    # =====================================================
    
    @pyqtSlot()
    def start_recording(self):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á (‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡πÑ‡∏°‡∏Ñ‡πå)"""
        print("[AssistantCore] üé§ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á...")
        self.status_updated.emit("üî¥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ü‡∏±‡∏á...")
        self.voice_recorder.start_recording()
    
    @pyqtSlot()
    def stop_recording(self):
        """‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á (‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏õ‡∏•‡πà‡∏≠‡∏¢‡∏õ‡∏∏‡πà‡∏°‡πÑ‡∏°‡∏Ñ‡πå)"""
        print("[AssistantCore] ‚èπÔ∏è ‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
        self.status_updated.emit("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...")
        self.voice_recorder.stop_recording()
    
    @pyqtSlot(object)
    def on_audio_recorded(self, audio_data):
        """‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡πâ‡∏ß ‚Üí ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        if audio_data is None or len(audio_data) == 0:
            self.status_updated.emit("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
            self.tts.speak("‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
            return
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á worker thread ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á
        self.transcription_worker = TranscriptionWorker(self.stt, audio_data)
        self.transcription_worker.transcription_done.connect(self.on_transcription_done)
        self.transcription_worker.start()
    
    @pyqtSlot(str)
    def on_transcription_done(self, text: str):
        """‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß"""
        if not text or text.strip() == "":
            self.status_updated.emit("‚ùå ‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à")
            self.tts.speak("‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à")
            return
        
        print(f"üìù ‡∏Ñ‡∏∏‡∏ì‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤: {text}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏ô GUI
        self.voice_input_received.emit(text)
        self.response_ready.emit(f"üìù ‡∏Ñ‡∏∏‡∏ì‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤: {text}")
        
        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á
        self.process_command(text)

    # =====================================================
    # üõë Stop Speaking Method
    # =====================================================
    
    @pyqtSlot()
    def stop_speaking(self):
        """
        ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö TTS Client ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏´‡∏¢‡∏∏‡∏î
        """
        print("[AssistantCore] ‚èπÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î...")
        
        # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó UI ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
        self.status_updated.emit("‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡πÅ‡∏•‡πâ‡∏ß")
        self.response_ready.emit("‚èπÔ∏è ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡πÅ‡∏•‡πâ‡∏ß")
        
        try:
            # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏¢‡∏∏‡∏î TTS
            if hasattr(self.tts, 'stop_speaking'):
                success = self.tts.stop_speaking()
                if success:
                    print("[AssistantCore] ‚úÖ ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                else:
                    print("[AssistantCore] ‚ùå ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            else:
                # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏™‡∏≥‡∏£‡∏≠‡∏á: ‡∏™‡∏£‡πâ‡∏≤‡∏á TTS ‡πÉ‡∏´‡∏°‡πà
                print("[AssistantCore] üîÑ ‡∏£‡∏µ‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á...")
                self.tts = TTSClient(lang="th")
                print("[AssistantCore] ‚úÖ ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (‡∏ß‡∏¥‡∏ò‡∏µ‡∏™‡∏≥‡∏£‡∏≠‡∏á)")
                
        except Exception as e:
            error_msg = f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏π‡∏î: {str(e)}"
            print(f"[AssistantCore] {error_msg}")

    # =====================================================
    # üß† Copilot Vision Methods
    # =====================================================
    
    def open_vision_panel(self, assistant_bar):
        """
        ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Copilot Vision
        """
        if not _HAS_MSS:
            self.status_updated.emit("‚ùå ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á mss: pip install mss")
            self.tts.speak("‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡∏£‡∏∞‡∏ö‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
            return
            
        self.vision_panel = ScreenSharePanel()
        self.vision_panel.share_requested.connect(
            lambda m, d: self.share_screen_to_ai(m, d, assistant_bar)
        )
        self.vision_panel.show()
        print("[Vision] ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠")

    def share_screen_to_ai(self, monitor_id, description, assistant_bar):
        """
        ‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏´‡πâ AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
        """
        assistant_bar.status_label.setText(f"üì° ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏ä‡∏£‡πå {description} ‡πÉ‡∏´‡πâ AI...")
        try:
            # ‡πÉ‡∏ä‡πâ vision system ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û
            reply = self.vision.ask_with_screenshot(
                f"‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡∏ö‡∏ô {description} ‡πÉ‡∏´‡πâ‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢",
                monitor=monitor_id
            )
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            assistant_bar.show_ai_response(f"ü§ñ [Vision-{monitor_id}]: {reply}")
            self.tts.speak(reply)
            assistant_bar.status_label.setText(f"‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå {description} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô context
            self.context.record_command(f"vision share {description}", "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            
        except Exception as e:
            error_msg = f"‚ùå ‡πÅ‡∏ä‡∏£‡πå‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}"
            assistant_bar.status_label.setText(error_msg)
            self.tts.speak("‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤")
            print(f"[Vision Error] {e}")

    # =====================================================
    # üéØ Command Processing Methods
    # =====================================================
    
    def handle_voice_f4(self):
        """‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å F4 (‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏° - ‡∏≠‡∏±‡∏î 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)"""
        try:
            self.status_updated.emit("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ü‡∏±‡∏á...")
            print("üé§ [F4] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ...")
            self.tts.speak("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ü‡∏±‡∏á‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö")
            user_input = self.stt.listen_once(duration=5)
            
            if not user_input or user_input.strip() == "":
                self.status_updated.emit("‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
                self.tts.speak("‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô")
                return

            print(f"üìù ‡∏Ñ‡∏∏‡∏ì‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤: {user_input}")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Context Memory
            context_suggestion = self.context.get_smart_suggestion(user_input)
            if "‡πÄ‡∏Ñ‡∏¢" in context_suggestion:
                print(f"üß† [Context] {context_suggestion}")
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏ô GUI
            self.voice_input_received.emit(user_input)
            
            # ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏õ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
            self.process_command(user_input)
            
        except Exception as e:
            error_msg = f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {str(e)}"
            self.response_ready.emit(error_msg)
            self.status_updated.emit("‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            print(f"[ERROR] {e}")
    
    @pyqtSlot(str)
    def process_command(self, command: str):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏à‡∏≤‡∏Å GUI ‡∏´‡∏£‡∏∑‡∏≠ Voice"""
        try:
            self.status_updated.emit("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...")
            
            # ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°
            if command.lower() in ["exit", "quit", "q"]:
                self.tts.speak("‡∏•‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö")
                self.status_updated.emit("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°...")
                QApplication.instance().quit()
                return
            
            # ‡πÅ‡∏™‡∏î‡∏á Context Summary
            if command.lower() in ["context", "‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥", "history"]:
                summary = self.context.get_context_summary()
                self.response_ready.emit(f"üß† [Context Memory] {summary}")
                self.tts.speak(f"‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {summary}")
                self.status_updated.emit("‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
                return
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°
            if self.command_parser.is_open_command(command):
                result = self.smart_app_launch(command)
                
                if result["ok"]:
                    app_name = self.command_parser.extract_app_name_from_command(command)
                    self.response_ready.emit(f"‚úÖ {result['message']}")
                    self.tts.speak(f"‡πÄ‡∏õ‡∏¥‡∏î {app_name} ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö")
                else:
                    self.response_ready.emit(f"‚ùå {result['message']}")
                    self.tts.speak("‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏ô‡∏µ‡πâ")
                self.status_updated.emit("‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
                return
            
            # Vision Mode
            if command.lower().startswith("vision"):
                self.process_vision_command(command)
                return
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á Automation
            if any(word in command.lower() for word in ["‡∏Ñ‡∏•‡∏¥‡∏Å", "‡∏û‡∏¥‡∏°‡∏û‡πå", "‡∏Å‡∏î", "‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô", "‡∏õ‡∏∏‡πà‡∏°"]):
                self.process_automation_command(command)
                return
            
            # ‡πÇ‡∏´‡∏°‡∏î‡πÅ‡∏ä‡∏ó‡∏õ‡∏Å‡∏ï‡∏¥
            if command.strip():
                self.process_chat_command(command)
                
        except Exception as e:
            error_msg = f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"
            self.response_ready.emit(error_msg)
            self.status_updated.emit("‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î")
            print(f"[ERROR] {e}")
    
    def smart_app_launch(self, raw_command: str) -> dict:
        """‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏õ‡∏¥‡∏î‡πÅ‡∏≠‡∏õ‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà"""
        print(f"üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: '{raw_command}'")
        
        app_name = self.command_parser.extract_app_name_from_command(raw_command)
        url = self.command_parser.extract_url(raw_command)
        search_query = self.command_parser.extract_search_query(raw_command)
        
        print(f"üìù ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°: '{app_name}'")
        if url:
            print(f"üîó URL: {url}")
        if search_query:
            print(f"üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {search_query}")
        
        result = self.smart_launcher.launch(app_name)
        
        # Fallback ‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏≤‡∏Å‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
        if not result["ok"] and (url or search_query):
            print(f"[Smart Fallback] ‡πÄ‡∏õ‡∏¥‡∏î URL ‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå...")
            browser = "chrome"
            final_url = url or search_query
            result = self.smart_launcher.launch(browser, final_url)
            
            if not result["ok"]:
                result = self.launcher.open_url(final_url, browser)
        
        if not result["ok"]:
            print(f"[Smart Fallback] ‡πÉ‡∏ä‡πâ AppLauncher ‡∏•‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á...")
            result = self.launcher.launch(app_name)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô context
        self.context.record_app_launch(app_name, result["ok"])
        self.context.record_command(f"‡πÄ‡∏õ‡∏¥‡∏î {app_name}", 
                                 "‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à" if result["ok"] else "‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß")
        
        return result
    
    def process_vision_command(self, command: str):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á Vision"""
        match = re.match(r'vision:?(\d*)\s*(.*)', command, re.IGNORECASE)
        if match:
            monitor_str = match.group(1)
            vision_prompt = match.group(2).strip()
            monitor = int(monitor_str) if monitor_str else 1
            if not vision_prompt:
                vision_prompt = "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏ô‡∏µ‡πâ"

            self.status_updated.emit(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡∏à‡∏≠‡∏ó‡∏µ‡πà {monitor}...")
            
            try:
                reply_text = self.vision.analyze(vision_prompt, monitor=monitor)
                self.context.record_command(f"vision: {vision_prompt}", "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û")
                self.response_ready.emit(f"ü§ñ ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ (Vision-{monitor}): {reply_text}")
                self.tts.speak(reply_text)
                self.status_updated.emit("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
            except Exception as e:
                error_msg = f"‚ùå {e}"
                self.response_ready.emit(error_msg)
                self.tts.speak("‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏û")
                self.status_updated.emit("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    
    def process_automation_command(self, command: str):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á Automation"""
        self.status_updated.emit("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£ Automation...")
        
        ocr_text = None
        data_uri = None
        if any(w in command.lower() for w in ["‡∏õ‡∏∏‡πà‡∏°", "‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠", "‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô"]):
            try:
                sr = ScreenReader(lang="tha+eng")
                img = screenshot_pil(monitor=1)
                ocr_text = sr.read_text(monitor=1)
                data_uri, _, _ = screenshot_data_uri(monitor=1, resize_to=(1200, 800))
            except Exception as e:
                print(f"[WARN] OCR/Vision ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°: {e}")

        ok, parsed = self.parser.parse(command, ocr_text=ocr_text, hint_image_data_uri=data_uri)
        if not ok:
            self.response_ready.emit("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÑ‡∏î‡πâ")
            self.tts.speak("‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á")
            self.status_updated.emit("‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            return

        result = self.executor.execute(parsed)
        self.context.record_command(command, 
                                 "‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à" if result.get("ok") else "‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß")
        
        if result.get("ok"):
            self.response_ready.emit(f"‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {result.get('message')}")
            self.tts.speak("‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö")
            self.status_updated.emit("Automation ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        else:
            self.response_ready.emit(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {result.get('message')}")
            self.tts.speak("‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ó‡∏≥‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            self.status_updated.emit("Automation ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    
    def process_chat_command(self, command: str):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÅ‡∏ä‡∏ó‡∏õ‡∏Å‡∏ï‡∏¥"""
        self.status_updated.emit("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö...")
        
        reply_text = self.llm.ask(command, history=self.chat_history)
        self.chat_history.append({"role": "user", "content": command})
        self.chat_history.append({"role": "assistant", "content": reply_text})
        self.context.record_command(command, "‡πÅ‡∏ä‡∏ó‡∏õ‡∏Å‡∏ï‡∏¥")
        
        self.response_ready.emit(f"ü§ñ ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢: {reply_text}")
        self.tts.speak(reply_text)
        self.status_updated.emit("‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")


def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÅ‡∏ö‡∏ö GUI - ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå"""
    app = QApplication(sys.argv)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á core system
    assistant_core = AssistantCore()
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á GUI
    assistant_bar = AssistantBar()
    
    # =====================================================
    # üîó ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    # =====================================================
    
    # ‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
    assistant_core.status_updated.connect(assistant_bar.status_label.setText)
    assistant_core.response_ready.connect(lambda text: print(f"ü§ñ: {text}"))
    assistant_core.voice_input_received.connect(assistant_bar.show_voice_input)
    
    # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏ã‡πâ‡∏≥
    assistant_core.response_ready.connect(
        lambda text: assistant_bar.show_ai_response(text, speak=False)
    )
    
    # ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å GUI ‡πÑ‡∏õ‡∏¢‡∏±‡∏á Core
    assistant_bar.text_submitted.connect(assistant_core.process_command)
    assistant_bar.close_requested.connect(app.quit)
    assistant_bar.mic_pressed.connect(assistant_core.start_recording)
    assistant_bar.mic_released.connect(assistant_core.stop_recording)
    assistant_bar.stop_speaking_requested.connect(assistant_core.stop_speaking)
    
    # ‚úÖ ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Copilot Vision
    # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏∏‡πà‡∏°‡πÉ‡∏ô GUI ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ assistant_core.open_vision_panel(assistant_bar)
    
    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö
    assistant_core.hotkey_listener.start()
    assistant_bar.show()
    # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏∏‡πà‡∏° Copilot Vision ‡πÉ‡∏ô AssistantBar
    assistant_bar.add_extra_button("üß† Copilot Vision", lambda: assistant_core.open_vision_panel(assistant_bar))

    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
    print("=" * 60)
    print("=== ü§ñ AI Assistant (Complete with Copilot Vision) ===")
    print("=" * 60)
    print("‚úÖ ‡∏Å‡∏î‡∏Ñ‡πâ‡∏≤‡∏á‡∏õ‡∏∏‡πà‡∏°‡πÑ‡∏°‡∏Ñ‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏û‡∏π‡∏î (Push-to-Talk)")
    print("‚úÖ ‡∏Å‡∏î F4 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
    print("‚úÖ ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏î Enter")
    print("‚úÖ ‡∏°‡∏µ‡∏õ‡∏∏‡πà‡∏°‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏π‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
    if _HAS_MSS:
        print("‚úÖ Copilot Vision ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏∏‡πà‡∏°‡πÉ‡∏ô GUI)")
    else:
        print("‚ö†Ô∏è  ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á mss ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Copilot Vision: pip install mss")
    
    assistant_core.status_updated.emit("‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‚úÖ")
    sys.exit(app.exec())


if __name__ == "__main__":
    main()