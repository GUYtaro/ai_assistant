# main.py
# ================================
# ü§ñ AI Assistant (Full Version with Complete Copilot Vision)
# ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Push-to-Talk, Copilot Vision, Continuous Vision, Interactive Vision
# ================================

import re
import sys
import urllib.parse
from PyQt6.QtWidgets import QApplication, QWidget, QVBoxLayout, QLabel, QPushButton, QHBoxLayout, QScrollArea, QFrame
from PyQt6.QtCore import QObject, pyqtSignal, pyqtSlot, QThread
from PyQt6.QtGui import QColor
import sounddevice as sd
import numpy as np

# Import core modules
from core.llm_client import LLMClient
from core.stt_client import STTClient
from core.tts_client import TTSClient
from core.vision_system import VisionSystem
from core.command_parser import CommandParser
from core.automation_executor import AutomationExecutor
from core.screen_capturer import screenshot_data_uri, screenshot_pil
from core.screen_reader import ScreenReader
from core.hotkey_listener import HotkeyListener
from core.app_launcher import AppLauncher
from core.smart_app_launcher import SmartAppLauncher 
from gui.assistant_bar import AssistantBar

# Import Vision Systems
try:
    from core.vision_overlay import VisionOverlay
    from core.continuous_vision_system import ContinuousVisionSystem
    from gui.interactive_vision_panel import InteractiveVisionPanel
    from core.live_vision_stream import LiveVisionStream
    from gui.live_vision_panel import LiveVisionPanel
    _HAS_VISION_SYSTEMS = True
except ImportError as e:
    print(f"[WARNING] ‡πÑ‡∏°‡πà‡∏û‡∏ö Vision Systems: {e}")
    _HAS_VISION_SYSTEMS = False

# Import for Copilot Vision
try:
    import mss
    _HAS_MSS = True
except ImportError:
    print("[WARNING] ‡πÑ‡∏°‡πà‡∏û‡∏ö mss, Copilot Vision ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
    _HAS_MSS = False


class ScreenSharePanel(QWidget):
    """
    üñ•Ô∏è ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Copilot Vision
    ‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏ä‡∏£‡πå‡πÉ‡∏´‡πâ AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    """
    
    share_requested = pyqtSignal(int, str)  # monitor_id, description

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("üß† Copilot Vision - Share Screen")
        self.setFixedSize(400, 400)
        self.layout = QVBoxLayout(self)

        # Title
        title = QLabel("üß† Copilot Vision")
        title.setStyleSheet("font-size:18px; font-weight:bold; margin:10px;")
        self.layout.addWidget(title)

        # Description
        desc = QLabel("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏ä‡∏£‡πå‡πÉ‡∏´‡πâ AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:")
        desc.setStyleSheet("margin:5px; color:#888;")
        self.layout.addWidget(desc)

        # Scroll area for monitors list
        self.scroll = QScrollArea()
        self.scroll.setWidgetResizable(True)
        self.layout.addWidget(self.scroll)

        # Content for scroll area
        content = QWidget()
        self.scroll.setWidget(content)
        vbox = QVBoxLayout(content)

        # Display available monitors
        if _HAS_MSS:
            with mss.mss() as sct:
                for i, mon in enumerate(sct.monitors[1:], start=1):
                    self._add_monitor_frame(vbox, i, mon)
        else:
            error_label = QLabel("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡πÑ‡∏î‡πâ\n‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á: pip install mss")
            error_label.setStyleSheet("color:red; margin:10px;")
            vbox.addWidget(error_label)

        vbox.addStretch()

        # Close button
        close_btn = QPushButton("‡∏õ‡∏¥‡∏î")
        close_btn.setStyleSheet("padding:8px; margin:10px;")
        close_btn.clicked.connect(self.close)
        self.layout.addWidget(close_btn)

    def _add_monitor_frame(self, layout, monitor_id, monitor_info):
        """‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ü‡∏£‡∏°‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠"""
        frame = QFrame()
        frame.setStyleSheet("""
            QFrame {
                border: 1px solid #555; 
                border-radius: 8px; 
                padding: 10px;
                margin: 5px;
                background: #2a2a2a;
            }
            QFrame:hover {
                background: #333333;
                border-color: #777;
            }
        """)
        
        frame_layout = QHBoxLayout(frame)

        # Monitor info
        info_text = f"üñ•Ô∏è ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ {monitor_id}\n{monitor_info['width']} x {monitor_info['height']} pixels"
        label = QLabel(info_text)
        label.setStyleSheet("font-size:12px;")
        frame_layout.addWidget(label)
        
        frame_layout.addStretch()
        
        # Share button
        btn = QPushButton("‡πÅ‡∏ä‡∏£‡πå")
        btn.setStyleSheet("""
            QPushButton {
                background: #4CAF50;
                color: white;
                border: none;
                padding: 6px 12px;
                border-radius: 4px;
                font-weight: bold;
            }
            QPushButton:hover {
                background: #45a049;
            }
        """)
        btn.clicked.connect(lambda _, m=monitor_id: self._on_share_clicked(m))
        frame_layout.addWidget(btn)
        
        layout.addWidget(frame)

    def _on_share_clicked(self, monitor_id):
        """‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡πÅ‡∏ä‡∏£‡πå‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠"""
        description = f"‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ {monitor_id}"
        print(f"[Vision] ‡πÅ‡∏ä‡∏£‡πå‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ {monitor_id} ‡πÉ‡∏´‡πâ AI")
        self.share_requested.emit(monitor_id, description)
        self.close()


class VoiceRecorder(QObject):
    """
    üé§ ‡∏ï‡∏±‡∏ß‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏ö‡∏ö Push-to-Talk
    """
    
    recording_started = pyqtSignal()
    recording_stopped = pyqtSignal(object)
    
    def __init__(self, stt_client: STTClient):
        super().__init__()
        self.stt = stt_client
        self.is_recording = False
        self.audio_data = []
        self.sample_rate = 16000
        
    def start_recording(self):
        if self.is_recording:
            return
        
        self.is_recording = True
        self.audio_data = []
        
        print("[VoiceRecorder] üî¥ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á...")
        self.recording_started.emit()
        
        def audio_callback(indata, frames, time, status):
            if status:
                print(f"[VoiceRecorder] Status: {status}")
            if self.is_recording:
                self.audio_data.append(indata.copy())
        
        self.stream = sd.InputStream(
            samplerate=self.sample_rate,
            channels=1,
            callback=audio_callback,
            dtype=np.float32
        )
        self.stream.start()
    
    def stop_recording(self):
        if not self.is_recording:
            return
        
        self.is_recording = False
        
        if hasattr(self, 'stream'):
            self.stream.stop()
            self.stream.close()
        
        print("[VoiceRecorder] ‚èπÔ∏è ‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
        
        if len(self.audio_data) == 0:
            print("[VoiceRecorder] ‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
            self.recording_stopped.emit(None)
            return
        
        audio_array = np.concatenate(self.audio_data, axis=0)
        audio_float32 = audio_array.flatten().astype(np.float32)
        
        duration = len(audio_float32) / self.sample_rate
        print(f"[VoiceRecorder] ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ {duration:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
        
        self.recording_stopped.emit(audio_float32)


class TranscriptionWorker(QThread):
    """
    üîÑ Worker thread ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
    """
    
    transcription_done = pyqtSignal(str)
    
    def __init__(self, stt_client: STTClient, audio_data):
        super().__init__()
        self.stt = stt_client
        self.audio_data = audio_data
    
    def run(self):
        try:
            print("[TranscriptionWorker] üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°...")
            
            text = self.stt.model.transcribe(
                self.audio_data,
                language="th",
                fp16=False
            )["text"].strip()
            
            print(f"[TranscriptionWorker] ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏î‡πâ: {text}")
            self.transcription_done.emit(text)
            
        except Exception as e:
            print(f"[TranscriptionWorker] ‚ùå Error: {e}")
            self.transcription_done.emit("")


class AssistantContext:
    """
    üß† Context Memory ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢
    """
    
    def __init__(self):
        self.memory = {
            "last_opened_app": None,
            "recent_commands": [],
            "favorite_apps": {},
            "user_preferences": {
                "preferred_browser": "chrome",
                "language": "th"
            }
        }
        self.max_history = 10
    
    def record_command(self, command: str, result: str):
        from datetime import datetime
        self.memory["recent_commands"].append({
            "command": command,
            "result": result,
            "timestamp": datetime.now().strftime("%H:%M:%S")
        })
        if len(self.memory["recent_commands"]) > self.max_history:
            self.memory["recent_commands"].pop(0)
    
    def record_app_launch(self, app_name: str, success: bool):
        self.memory["last_opened_app"] = app_name
        if app_name not in self.memory["favorite_apps"]:
            self.memory["favorite_apps"][app_name] = {"launch_count": 0, "success_count": 0}
        self.memory["favorite_apps"][app_name]["launch_count"] += 1
        if success:
            self.memory["favorite_apps"][app_name]["success_count"] += 1
    
    def get_smart_suggestion(self, partial_command: str) -> str:
        partial_lower = partial_command.lower()
        
        for cmd in reversed(self.memory["recent_commands"]):
            if partial_lower in cmd["command"].lower():
                return f"‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ô‡∏µ‡πâ: '{cmd['command']}' -> {cmd['result']}"
        
        for app_name, stats in self.memory["favorite_apps"].items():
            if partial_lower in app_name.lower():
                success_rate = (stats["success_count"] / stats["launch_count"]) * 100
                return f"‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏õ‡∏¥‡∏î '{app_name}' {stats['launch_count']} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á (‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à {success_rate:.0f}%)"
        
        return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"
    
    def get_context_summary(self) -> str:
        summary = []
        if self.memory["last_opened_app"]:
            summary.append(f"‡πÄ‡∏õ‡∏¥‡∏î‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {self.memory['last_opened_app']}")
        if self.memory["recent_commands"]:
            summary.append(f"‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {len(self.memory['recent_commands'])} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        if self.memory["favorite_apps"]:
            top_app = max(self.memory["favorite_apps"].items(), 
                         key=lambda x: x[1]["launch_count"], default=(None, None))
            if top_app[0]:
                summary.append(f"‡πÅ‡∏≠‡∏õ‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°: {top_app[0]}")
        return " | ".join(summary) if summary else "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î"


class SmartCommandParser:
    """
    üß© ‡∏ï‡∏±‡∏ß‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞
    """
    
    def __init__(self, llm_client):
        self.llm = llm_client
        self.thai_to_english_map = {
            "‡∏î‡∏¥‡∏™‡∏Ñ‡∏≠‡∏£‡πå‡∏ï": "discord", "‡∏î‡∏¥‡∏™‡∏Ñ‡∏≠‡∏£‡πå‡∏î": "discord", "‡∏î‡∏¥‡∏™‡∏Ñ‡∏≠‡∏î": "discord",
            "‡πÑ‡∏•‡∏ô‡πå": "line", "‡∏•‡∏≤‡∏¢": "line",
            "‡∏™‡∏õ‡∏≠‡∏ï‡∏¥‡πÑ‡∏ü": "spotify", "‡∏™‡∏õ‡∏≠‡∏ï‡∏ï‡∏¥‡∏ü‡∏≤‡∏¢": "spotify",
            "‡πÇ‡∏Ñ‡∏£‡∏°": "chrome", "‡πÑ‡∏Ñ‡∏£‡∏°‡πå": "chrome",
            "‡πÄ‡∏≠‡πá‡∏î‡∏à‡πå": "edge", "‡∏ü‡∏≤‡∏¢‡∏£‡πå‡∏ü‡∏≠‡∏Å‡∏ã‡πå": "firefox",
            "‡∏™‡∏ï‡∏µ‡∏°": "steam", "‡∏ß‡∏µ‡πÄ‡∏≠‡∏™‡πÇ‡∏Ñ‡πâ‡∏î": "vscode",
            "‡πÇ‡∏ô‡πâ‡∏ï‡πÅ‡∏û‡∏î": "notepad", "‡πÅ‡∏Ñ‡∏•‡∏Ñ‡∏π‡πÄ‡∏•‡πÄ‡∏ï‡∏≠‡∏£‡πå": "calculator",
            "‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏¥‡∏î‡πÄ‡∏•‡∏Ç": "calculator", "‡πÄ‡∏û‡πâ‡∏ô‡∏ó‡πå": "paint",
            "‡πÇ‡∏£‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏ã‡πå": "roblox", "‡∏°‡∏≤‡∏¢‡∏Ñ‡∏£‡∏≤‡∏ü‡∏ó‡πå": "minecraft",
            "‡∏ß‡∏≠‡∏£‡πå‡∏ò‡∏±‡∏ô‡πÄ‡∏î‡∏≠‡∏£‡πå": "war thunder", "‡∏ß‡∏µ‡πÄ‡∏≠‡πá‡∏°‡πÅ‡∏ß‡∏£‡πå": "vmware",
            "‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏î": "word", "‡πÄ‡∏≠‡πá‡∏Å‡πÄ‡∏ã‡∏•": "excel",
            "‡∏û‡∏≤‡∏ß‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏û‡∏≠‡∏¢‡∏ó‡πå": "powerpoint", "‡πÄ‡∏≠‡∏≤‡∏ó‡πå‡∏•‡∏∏‡∏Ñ": "outlook",
            "‡∏ó‡∏µ‡∏°‡∏™‡πå": "teams", "‡∏ã‡∏π‡∏°": "zoom", "‡∏™‡πÅ‡∏•‡πá‡∏Å": "slack",
            "‡∏°‡∏≤‡∏¢‡πÄ‡∏≠‡∏ã‡∏∏‡∏™": "my asus", "‡∏≠‡∏≤‡∏£‡πå‡∏°‡∏π‡∏£‡∏µ‡πà‡πÄ‡∏Ñ‡∏£‡∏ó": "armoury crate"
        }
    
    def is_open_command(self, text: str) -> bool:
        return any(word in text.lower() for word in ["‡πÄ‡∏õ‡∏¥‡∏î", "open", "launch", "start", "run"])
    
    def extract_app_name_from_command(self, text: str) -> str:
        text_lower = text.lower()
        remove_words = ["‡πÄ‡∏õ‡∏¥‡∏î", "open", "launch", "start", "run", "‡∏ú‡πà‡∏≤‡∏ô", "‡πÉ‡∏ô", "‡∏î‡πâ‡∏ß‡∏¢", "‡∏´‡∏ô‡πà‡∏≠‡∏¢"]
        app_name = text_lower
        for word in remove_words:
            app_name = app_name.replace(word, "").strip()
        app_name_english = self._translate_thai_to_english(app_name)
        if app_name_english != app_name:
            print(f"üîÑ [Translation] '{app_name}' ‚Üí '{app_name_english}'")
        return app_name_english
    
    def _translate_thai_to_english(self, thai_text: str) -> str:
        thai_text = thai_text.strip()
        if thai_text in self.thai_to_english_map:
            return self.thai_to_english_map[thai_text]
        for thai, english in self.thai_to_english_map.items():
            if thai in thai_text:
                return english
        return thai_text
    
    def extract_url(self, text: str) -> str:
        url_map = {
            "youtube": "https://youtube.com", "‡∏¢‡∏π‡∏ó‡∏π‡∏õ": "https://youtube.com",
            "google": "https://google.com", "facebook": "https://facebook.com",
            "chatgpt": "https://chat.openai.com", "claude": "https://claude.ai"
        }
        for keyword, url in url_map.items():
            if keyword in text.lower():
                return url
        return None
    
    def extract_search_query(self, text: str) -> str:
        if "‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤" not in text.lower() and "search" not in text.lower():
            return None
        query = text.lower().replace("‡πÄ‡∏õ‡∏¥‡∏î", "").replace("‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤", "").strip()
        if query:
            return f"https://www.google.com/search?q={urllib.parse.quote(query)}"
        return None


class AssistantCore(QObject):
    """
    üß† Core System ‡∏Ç‡∏≠‡∏á AI Assistant (Full Version with Complete Vision)
    """
    
    status_updated = pyqtSignal(str)
    response_ready = pyqtSignal(str)
    voice_input_received = pyqtSignal(str)
    
    def __init__(self):
        super().__init__()
        self.setup_core_systems()
        
    def setup_core_systems(self):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
        try:
            # Core modules
            self.llm = LLMClient()
            self.stt = STTClient(model_size="medium", language="th")
            self.tts = TTSClient(lang="th")
            self.vision = VisionSystem()
            self.parser = CommandParser(llm_client=self.llm)
            self.executor = AutomationExecutor(monitor=1)
            self.launcher = AppLauncher()
            self.smart_launcher = SmartAppLauncher()
            
            # Additional systems
            self.context = AssistantContext()
            self.command_parser = SmartCommandParser(llm_client=self.llm)
            
            # Voice Recorder
            self.voice_recorder = VoiceRecorder(self.stt)
            self.voice_recorder.recording_stopped.connect(self.on_audio_recorded)
            
            # Chat history
            self.chat_history = [{
                "role": "system", 
                "content": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥"
            }]
            
            # Hotkey Listener
            self.hotkey_listener = HotkeyListener(
                callback_start=self.handle_voice_f4,
                hotkey="f4",
                cooldown=2.0
            )
            
            # ‚úÖ Setup Vision Systems
            self.setup_vision_systems()
            
            self.status_updated.emit("‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‚úÖ")
            print("=== ü§ñ AI Assistant (Complete with Full Copilot Vision) ===")
            
        except Exception as e:
            error_msg = f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö: {str(e)}"
            self.status_updated.emit(error_msg)
            print(f"Error setting up systems: {e}")

    def setup_vision_systems(self):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö Vision ‡∏Ñ‡∏£‡∏ö‡∏ä‡∏∏‡∏î"""
        if not _HAS_VISION_SYSTEMS:
            print("[Vision] ‚ö†Ô∏è Vision Systems ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏° - ‡∏Ç‡πâ‡∏≤‡∏°")
            self.vision_overlay = None
            self.continuous_vision = None
            self.interactive_panel = None
            return
            
        try:
            # 1Ô∏è‚É£ Vision Overlay
            self.vision_overlay = VisionOverlay()
            self.vision_overlay.clicked.connect(self.on_overlay_clicked)
            print("[Vision] ‚úÖ Overlay System")
            
            # 2Ô∏è‚É£ Continuous Vision
            self.continuous_vision = ContinuousVisionSystem(
                llm_client=self.llm,
                monitor=1
            )
            self.continuous_vision.analysis_ready.connect(self.on_continuous_analysis)
            self.continuous_vision.change_detected.connect(self.on_screen_change)
            print("[Vision] ‚úÖ Continuous System")
            
            # 3Ô∏è‚É£ Interactive Vision Panel
            self.interactive_panel = None  # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
            print("[Vision] ‚úÖ Interactive System (standby)")
            
        except Exception as e:
            print(f"[Vision] ‚ùå Setup Error: {e}")
            self.vision_overlay = None
            self.continuous_vision = None
            self.interactive_panel = None

    # =====================================================
    # üé§ Voice Recording Methods
    # =====================================================
    
    @pyqtSlot()
    def start_recording(self):
        print("[AssistantCore] üé§ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á...")
        self.status_updated.emit("üî¥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ü‡∏±‡∏á...")
        self.voice_recorder.start_recording()
    
    @pyqtSlot()
    def stop_recording(self):
        print("[AssistantCore] ‚èπÔ∏è ‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
        self.status_updated.emit("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...")
        self.voice_recorder.stop_recording()
    
    @pyqtSlot(object)
    def on_audio_recorded(self, audio_data):
        if audio_data is None or len(audio_data) == 0:
            self.status_updated.emit("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
            self.tts.speak("‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
            return
        
        self.transcription_worker = TranscriptionWorker(self.stt, audio_data)
        self.transcription_worker.transcription_done.connect(self.on_transcription_done)
        self.transcription_worker.start()
    
    @pyqtSlot(str)
    def on_transcription_done(self, text: str):
        if not text or text.strip() == "":
            self.status_updated.emit("‚ùå ‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à")
            self.tts.speak("‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à")
            return
        
        print(f"üìù ‡∏Ñ‡∏∏‡∏ì‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤: {text}")
        self.voice_input_received.emit(text)
        self.response_ready.emit(f"üìù ‡∏Ñ‡∏∏‡∏ì‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤: {text}")
        self.process_command(text)

    # =====================================================
    # üõë Stop Speaking
    # =====================================================
    
    @pyqtSlot()
    def stop_speaking(self):
        print("[AssistantCore] ‚èπÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î...")
        self.status_updated.emit("‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡πÅ‡∏•‡πâ‡∏ß")
        self.response_ready.emit("‚èπÔ∏è ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡πÅ‡∏•‡πâ‡∏ß")
        
        try:
            if hasattr(self.tts, 'stop_speaking'):
                self.tts.stop_speaking()
            else:
                self.tts = TTSClient(lang="th")
        except Exception as e:
            print(f"[AssistantCore] ‚ùå Stop Error: {e}")

    # =====================================================
    # üé® Vision Overlay Methods
    # =====================================================
    
    def show_ui_hints(self, elements):
        """‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≠‡∏ö‡∏ä‡∏µ‡πâ UI elements"""
        if not self.vision_overlay:
            print("[Vision] ‚ö†Ô∏è Vision Overlay ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°")
            return
            
        self.vision_overlay.clear_annotations()
        
        for elem in elements:
            self.vision_overlay.add_box(
                elem["x"], elem["y"], elem["w"], elem["h"],
                label=elem.get("label", ""),
                color=QColor(100, 255, 100, 200)
            )
        
        self.vision_overlay.show_temporary(duration_ms=5000)
        print(f"[Vision] üé® ‡πÅ‡∏™‡∏î‡∏á {len(elements)} elements")
    
    @pyqtSlot(int, int)
    def on_overlay_clicked(self, x, y):
        print(f"[Vision] üëÜ ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ó‡∏µ‡πà ({x}, {y})")
        self.response_ready.emit(f"üñ±Ô∏è ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ó‡∏µ‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á ({x}, {y})")

    # =====================================================
    # üëÅÔ∏è Continuous Vision Methods
    # =====================================================
    
    def start_continuous_vision(self, interval=5):
        if not self.continuous_vision:
            print("[Vision] ‚ö†Ô∏è Continuous Vision ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°")
            self.status_updated.emit("‚ùå Continuous Vision ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°")
            return
            
        self.continuous_vision.start(interval_seconds=interval)
        self.status_updated.emit(f"üîÑ Continuous Vision (‡∏ó‡∏∏‡∏Å {interval}s)")
        self.tts.speak(f"‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏ó‡∏∏‡∏Å {interval} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
    
    def stop_continuous_vision(self):
        if not self.continuous_vision:
            return
            
        self.continuous_vision.stop()
        self.status_updated.emit("‚è∏Ô∏è ‡∏´‡∏¢‡∏∏‡∏î Continuous Vision")
        self.tts.speak("‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡πâ‡∏ß")
    
    @pyqtSlot(str)
    def on_continuous_analysis(self, analysis):
        print(f"[ContinuousVision] ü§ñ {analysis[:100]}...")
        self.response_ready.emit(f"üîÑ {analysis}")
    
    @pyqtSlot(float, str)
    def on_screen_change(self, percent, description):
        print(f"[ContinuousVision] üîî ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á {percent:.1f}%")
        self.response_ready.emit(f"üîî ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á {percent:.1f}%")

    # =====================================================
    # üñ±Ô∏è Interactive Vision Methods
    # =====================================================
    
    def open_interactive_vision(self):
        if not _HAS_VISION_SYSTEMS:
            print("[Vision] ‚ö†Ô∏è Interactive Vision ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°")
            self.status_updated.emit("‚ùå Interactive Vision ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°")
            return
            
        if self.interactive_panel is None:
            self.interactive_panel = InteractiveVisionPanel()
            self.interactive_panel.point_selected.connect(self.on_point_selected)
            self.interactive_panel.region_selected.connect(self.on_region_selected)
            self.interactive_panel.close_requested.connect(
                lambda: self.interactive_panel.hide()
            )
        
        self.interactive_panel.show()
        self.status_updated.emit("üñ±Ô∏è Interactive Vision Mode")
        print("[Vision] üñ±Ô∏è ‡πÄ‡∏õ‡∏¥‡∏î‡πÇ‡∏´‡∏°‡∏î Interactive")
    
    @pyqtSlot(int, int, str)
    def on_point_selected(self, x, y, mode):
        print(f"[InteractiveVision] üëÜ ({x}, {y}) - {mode}")
        
        data_uri, _, img = screenshot_data_uri(monitor=1)
        
        prompts = {
            "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢": f"‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏≠‡∏ö‡πÜ ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á ({x}, {y}) ‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏ô‡∏µ‡πâ",
            "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå": f"‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ß‡πà‡∏≤‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á ({x}, {y}) ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£",
            "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥": f"‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡∏±‡∏ö‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á ({x}, {y})",
            "‡∏´‡∏≤ Element": f"‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á ({x}, {y}) ‡∏Ñ‡∏∑‡∏≠ UI element ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÉ‡∏î",
            "‡∏ó‡∏≥‡∏á‡∏≤‡∏ô": f"‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÇ‡∏ï‡πâ‡∏ï‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á ({x}, {y})"
        }
        
        prompt = prompts.get(mode, prompts["‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢"])
        
        self.status_updated.emit(f"üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ({x}, {y})...")
        reply = self.llm.ask_with_image(prompt, data_uri)
        
        self.response_ready.emit(f"ü§ñ [{mode}] {reply}")
        self.tts.speak(reply)
        
        if self.vision_overlay:
            self.vision_overlay.clear_annotations()
            self.vision_overlay.add_text(x + 10, y - 10, "üëÜ ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà")
            self.vision_overlay.show_temporary(3000)
    
    @pyqtSlot(int, int, int, int, str)
    def on_region_selected(self, x, y, w, h, mode):
        print(f"[InteractiveVision] üì¶ ({x}, {y}, {w}, {h}) - {mode}")
        
        region = (x, y, w, h)
        data_uri, _, img = screenshot_data_uri(region=region, monitor=1)
        
        prompts = {
            "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢": "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡πÉ‡∏ô‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î",
            "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå": "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ ‡πÅ‡∏•‡∏∞‡∏ö‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢",
            "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥": "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡∏±‡∏ö‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡πÉ‡∏ô‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ",
            "‡∏´‡∏≤ Element": "‡∏£‡∏∞‡∏ö‡∏∏ UI elements ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡πÉ‡∏ô‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ",
            "‡∏ó‡∏≥‡∏á‡∏≤‡∏ô": "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡πÉ‡∏ô‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ"
        }
        
        prompt = prompts.get(mode, prompts["‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢"])
        
        self.status_updated.emit(f"üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà {w}x{h}px...")
        reply = self.llm.ask_with_image(prompt, data_uri)
        
        self.response_ready.emit(f"ü§ñ [{mode}] {reply}")
        self.tts.speak(reply)
        
        if self.vision_overlay:
            self.vision_overlay.clear_annotations()
            self.vision_overlay.add_box(x, y, w, h, f"{w}x{h}px")
            self.vision_overlay.show_temporary(5000)

    # =====================================================
    # üß† Copilot Vision (Original)
    # =====================================================
    
    def open_vision_panel(self, assistant_bar):
        """‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Copilot Vision"""
        if not _HAS_MSS:
            self.status_updated.emit("‚ùå ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á mss: pip install mss")
            self.tts.speak("‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡∏£‡∏∞‡∏ö‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
            return
            
        self.vision_panel = ScreenSharePanel()
        self.vision_panel.share_requested.connect(
            lambda m, d: self.share_screen_to_ai(m, d, assistant_bar)
        )
        self.vision_panel.show()
        print("[Vision] ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠")

    def share_screen_to_ai(self, monitor_id, description, assistant_bar):
        """‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏´‡πâ AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå"""
        assistant_bar.status_label.setText(f"üì° ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏ä‡∏£‡πå {description} ‡πÉ‡∏´‡πâ AI...")
        try:
            reply = self.vision.ask_with_screenshot(
                f"‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡∏ö‡∏ô {description} ‡πÉ‡∏´‡πâ‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢",
                monitor=monitor_id
            )
            
            assistant_bar.show_ai_response(f"ü§ñ [Vision-{monitor_id}]: {reply}")
            self.tts.speak(reply)
            assistant_bar.status_label.setText(f"‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå {description} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            
            self.context.record_command(f"vision share {description}", "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            
        except Exception as e:
            error_msg = f"‚ùå ‡πÅ‡∏ä‡∏£‡πå‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}"
            assistant_bar.status_label.setText(error_msg)
            self.tts.speak("‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤")
            print(f"[Vision Error] {e}")

    # =====================================================
    # üéØ Command Processing
    # =====================================================
    
    def handle_voice_f4(self):
        """‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å F4"""
        try:
            self.status_updated.emit("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ü‡∏±‡∏á...")
            print("üé§ [F4] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ...")
            self.tts.speak("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ü‡∏±‡∏á‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö")
            user_input = self.stt.listen_once(duration=5)
            
            if not user_input or user_input.strip() == "":
                self.status_updated.emit("‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
                self.tts.speak("‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô")
                return

            print(f"üìù ‡∏Ñ‡∏∏‡∏ì‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤: {user_input}")
            
            context_suggestion = self.context.get_smart_suggestion(user_input)
            if "‡πÄ‡∏Ñ‡∏¢" in context_suggestion:
                print(f"üß† [Context] {context_suggestion}")
            
            self.voice_input_received.emit(user_input)
            self.process_command(user_input)
            
        except Exception as e:
            error_msg = f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {str(e)}"
            self.response_ready.emit(error_msg)
            self.status_updated.emit("‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            print(f"[ERROR] {e}")
    
    @pyqtSlot(str)
    def process_command(self, command: str):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
        try:
            self.status_updated.emit("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...")
            cmd_lower = command.lower()
            
            # ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°
            if cmd_lower in ["exit", "quit", "q"]:
                self.tts.speak("‡∏•‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö")
                self.status_updated.emit("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°...")
                QApplication.instance().quit()
                return
            
            # ‡πÅ‡∏™‡∏î‡∏á Context
            if cmd_lower in ["context", "‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥", "history"]:
                summary = self.context.get_context_summary()
                self.response_ready.emit(f"üß† [Context Memory] {summary}")
                self.tts.speak(f"‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {summary}")
                self.status_updated.emit("‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
                return
            
            # ‚úÖ ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á Vision Systems
            if "continuous vision" in cmd_lower or "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á" in cmd_lower:
                if "start" in cmd_lower or "‡πÄ‡∏£‡∏¥‡πà‡∏°" in cmd_lower:
                    self.start_continuous_vision(interval=5)
                elif "stop" in cmd_lower or "‡∏´‡∏¢‡∏∏‡∏î" in cmd_lower:
                    self.stop_continuous_vision()
                return
            
            if "interactive vision" in cmd_lower or "‡πÇ‡∏´‡∏°‡∏î‡πÇ‡∏ï‡πâ‡∏ï‡∏≠‡∏ö" in cmd_lower:
                self.open_interactive_vision()
                return
            
            if "show hints" in cmd_lower or "‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥" in cmd_lower:
                from core.ui_detector import UIDetector
                detector = UIDetector(monitor=1)
                elements = detector.find_all_text()[:10]
                
                hints = []
                for elem in elements:
                    hints.append({
                        "x": elem["x"],
                        "y": elem["y"],
                        "w": elem["w"],
                        "h": elem["h"],
                        "label": elem["text"][:20]
                    })
                
                self.show_ui_hints(hints)
                self.response_ready.emit(f"‚úÖ ‡πÅ‡∏™‡∏î‡∏á {len(hints)} UI elements")
                return
            
            # ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°
            if self.command_parser.is_open_command(command):
                result = self.smart_app_launch(command)
                
                if result["ok"]:
                    app_name = self.command_parser.extract_app_name_from_command(command)
                    self.response_ready.emit(f"‚úÖ {result['message']}")
                    self.tts.speak(f"‡πÄ‡∏õ‡∏¥‡∏î {app_name} ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö")
                else:
                    self.response_ready.emit(f"‚ùå {result['message']}")
                    self.tts.speak("‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏ô‡∏µ‡πâ")
                self.status_updated.emit("‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
                return
            
            # Vision Mode
            if cmd_lower.startswith("vision"):
                self.process_vision_command(command)
                return
            
            # Automation
            if any(word in cmd_lower for word in ["‡∏Ñ‡∏•‡∏¥‡∏Å", "‡∏û‡∏¥‡∏°‡∏û‡πå", "‡∏Å‡∏î", "‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô", "‡∏õ‡∏∏‡πà‡∏°"]):
                self.process_automation_command(command)
                return
            
            # ‡πÇ‡∏´‡∏°‡∏î‡πÅ‡∏ä‡∏ó‡∏õ‡∏Å‡∏ï‡∏¥
            if command.strip():
                self.process_chat_command(command)
                
        except Exception as e:
            error_msg = f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"
            self.response_ready.emit(error_msg)
            self.status_updated.emit("‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î")
            print(f"[ERROR] {e}")
    
    def smart_app_launch(self, raw_command: str) -> dict:
        """‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏õ‡∏¥‡∏î‡πÅ‡∏≠‡∏õ‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞"""
        print(f"üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: '{raw_command}'")
        
        app_name = self.command_parser.extract_app_name_from_command(raw_command)
        url = self.command_parser.extract_url(raw_command)
        search_query = self.command_parser.extract_search_query(raw_command)
        
        print(f"üìù ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°: '{app_name}'")
        if url:
            print(f"üîó URL: {url}")
        if search_query:
            print(f"üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {search_query}")
        
        result = self.smart_launcher.launch(app_name)
        
        if not result["ok"] and (url or search_query):
            print(f"[Smart Fallback] ‡πÄ‡∏õ‡∏¥‡∏î URL ‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå...")
            browser = "chrome"
            final_url = url or search_query
            result = self.smart_launcher.launch(browser, final_url)
            
            if not result["ok"]:
                result = self.launcher.open_url(final_url, browser)
        
        if not result["ok"]:
            print(f"[Smart Fallback] ‡πÉ‡∏ä‡πâ AppLauncher ‡∏•‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á...")
            result = self.launcher.launch(app_name)
        
        self.context.record_app_launch(app_name, result["ok"])
        self.context.record_command(f"‡πÄ‡∏õ‡∏¥‡∏î {app_name}", 
                                 "‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à" if result["ok"] else "‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß")
        
        return result
    
    def process_vision_command(self, command: str):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á Vision"""
        match = re.match(r'vision:?(\d*)\s*(.*)', command, re.IGNORECASE)
        if match:
            monitor_str = match.group(1)
            vision_prompt = match.group(2).strip()
            monitor = int(monitor_str) if monitor_str else 1
            if not vision_prompt:
                vision_prompt = "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏ô‡∏µ‡πâ"

            self.status_updated.emit(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡∏à‡∏≠‡∏ó‡∏µ‡πà {monitor}...")
            
            try:
                reply_text = self.vision.analyze(vision_prompt, monitor=monitor)
                self.context.record_command(f"vision: {vision_prompt}", "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û")
                self.response_ready.emit(f"ü§ñ ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ (Vision-{monitor}): {reply_text}")
                self.tts.speak(reply_text)
                self.status_updated.emit("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
            except Exception as e:
                error_msg = f"‚ùå {e}"
                self.response_ready.emit(error_msg)
                self.tts.speak("‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏û")
                self.status_updated.emit("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    
    def process_automation_command(self, command: str):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á Automation"""
        self.status_updated.emit("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£ Automation...")
        
        ocr_text = None
        data_uri = None
        if any(w in command.lower() for w in ["‡∏õ‡∏∏‡πà‡∏°", "‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠", "‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô"]):
            try:
                sr = ScreenReader(lang="tha+eng")
                img = screenshot_pil(monitor=1)
                ocr_text = sr.read_text(monitor=1)
                data_uri, _, _ = screenshot_data_uri(monitor=1, resize_to=(1200, 800))
            except Exception as e:
                print(f"[WARN] OCR/Vision ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°: {e}")

        ok, parsed = self.parser.parse(command, ocr_text=ocr_text, hint_image_data_uri=data_uri)
        if not ok:
            self.response_ready.emit("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÑ‡∏î‡πâ")
            self.tts.speak("‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á")
            self.status_updated.emit("‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            return

        result = self.executor.execute(parsed)
        self.context.record_command(command, 
                                 "‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à" if result.get("ok") else "‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß")
        
        if result.get("ok"):
            self.response_ready.emit(f"‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {result.get('message')}")
            self.tts.speak("‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö")
            self.status_updated.emit("Automation ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        else:
            self.response_ready.emit(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {result.get('message')}")
            self.tts.speak("‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ó‡∏≥‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            self.status_updated.emit("Automation ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    
    def process_chat_command(self, command: str):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÅ‡∏ä‡∏ó‡∏õ‡∏Å‡∏ï‡∏¥"""
        self.status_updated.emit("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö...")
        
        reply_text = self.llm.ask(command, history=self.chat_history)
        self.chat_history.append({"role": "user", "content": command})
        self.chat_history.append({"role": "assistant", "content": reply_text})
        self.context.record_command(command, "‡πÅ‡∏ä‡∏ó‡∏õ‡∏Å‡∏ï‡∏¥")
        
        self.response_ready.emit(f"ü§ñ ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢: {reply_text}")
        self.tts.speak(reply_text)
        self.status_updated.emit("‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")


def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å - Full Version"""
    app = QApplication(sys.argv)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á core system
    assistant_core = AssistantCore()
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á GUI
    assistant_bar = AssistantBar()
    
    # ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì
    assistant_core.status_updated.connect(assistant_bar.status_label.setText)
    assistant_core.response_ready.connect(lambda text: print(f"ü§ñ: {text}"))
    assistant_core.voice_input_received.connect(assistant_bar.show_voice_input)
    assistant_core.response_ready.connect(
        lambda text: assistant_bar.show_ai_response(text, speak=False)
    )
    
    assistant_bar.text_submitted.connect(assistant_core.process_command)
    assistant_bar.close_requested.connect(app.quit)
    assistant_bar.mic_pressed.connect(assistant_core.start_recording)
    assistant_bar.mic_released.connect(assistant_core.stop_recording)
    assistant_bar.stop_speaking_requested.connect(assistant_core.stop_speaking)
    
    # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏∏‡πà‡∏° Vision ‡∏Ñ‡∏£‡∏ö‡∏ä‡∏∏‡∏î
    assistant_bar.add_extra_button(
        "üß† Copilot",
        lambda: assistant_core.open_vision_panel(assistant_bar)
    )
    
    if _HAS_VISION_SYSTEMS:
        assistant_bar.add_extra_button(
            "üîÑ Continuous",
            lambda: assistant_core.start_continuous_vision(5)
        )
        
        assistant_bar.add_extra_button(
            "üñ±Ô∏è Interactive",
            lambda: assistant_core.open_interactive_vision()
        )
        
        assistant_bar.add_extra_button(
            "üé® Hints",
            lambda: assistant_core.process_command("show hints")
        )
    
    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö
    assistant_core.hotkey_listener.start()
    assistant_bar.show()
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
    print("=" * 70)
    print("=== ü§ñ AI Assistant with Full Copilot Vision ===")
    print("=" * 70)
    print("‚úÖ üß† Copilot - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
    if _HAS_VISION_SYSTEMS:
        print("‚úÖ üîÑ Continuous - ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á")
        print("‚úÖ üñ±Ô∏è Interactive - ‡∏Ñ‡∏•‡∏¥‡∏Å/‡∏•‡∏≤‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ñ‡∏≤‡∏° AI")
        print("‚úÖ üé® Hints - ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≠‡∏ö UI elements")
    print("‚úÖ üé§ Push-to-Talk - ‡∏Å‡∏î‡∏Ñ‡πâ‡∏≤‡∏á‡πÑ‡∏°‡∏Ñ‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏û‡∏π‡∏î")
    print("‚úÖ ‚å®Ô∏è F4 - ‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
    print("=" * 70)
    
    assistant_core.status_updated.emit("‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‚úÖ")
    sys.exit(app.exec())


if __name__ == "__main__":
    main()